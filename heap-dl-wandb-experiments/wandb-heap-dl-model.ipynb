{
  "cells":[
    {
      "cell_type":"markdown",
      "source":[
        "# HEAP-DL wandb.ai Experiments"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.style as style\n",
        "import plotly.express as px\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## Data Loading"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "DATA_PATH='data\/clean\/model_input.csv'"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "df = pd.read_csv(DATA_PATH,delimiter=\"|\", usecols=[\"quarter\",\"duration\",\"rectype\",\"pos\",\"pat_age\", \"der_sex\",\"dispense_fee\",\"copay\", \"paid\",\"age_group\",\"bill_spec\",\"formulary\"])"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "df.describe(include='all').T"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "for i in df.columns:\n",
        "    print(\"Column name {} and unique values are {}\".format(i,len(df[i].unique())))"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "df.info()"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Create a column that represents the total cost = paid + copay + dispense_fee\n",
        "target_columns = ['paid', 'copay', 'dispense_fee']\n",
        "df['target'] = (df.loc[:, target_columns]).sum(axis='columns')"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Categorical Features"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "cat_features=[\"quarter\",\"duration\",\"rectype\",\"bill_spec\", \"pos\",\"der_sex\",\"age_group\",\"formulary\"]\n",
        "out_feature=\"target\"\n",
        "cat_features"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "df[\"pos\"] = df[\"pos\"].astype(\"str\")\n",
        "df[\"age_group\"] = df[\"age_group\"].astype(\"str\")"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Label Encoding of Categorical Features"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn.preprocessing import LabelEncoder\n",
        "lbl_encoders={}\n",
        "for feature in cat_features:\n",
        "    print(feature)\n",
        "    lbl_encoders[feature]=LabelEncoder()\n",
        "    df[feature]=lbl_encoders[feature].fit_transform(df[feature])"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Scaling Numerical & Target columns"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import QuantileTransformer # Try\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "#  Need to determine the scaler\n",
        "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "scaler = RobustScaler()\n",
        "df['target'] = scaler.fit_transform(df['target'].values.reshape(-1,1))\n",
        "df['pat_age'] = scaler.fit_transform(df['pat_age'].values.reshape(-1,1))\n",
        "plt.title(\"Distribution of Charges\")\n",
        "sns.kdeplot(df['target'])"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def find_outliers_claims(x):\n",
        "    q1 = np.percentile(x,25)\n",
        "    q3 = np.percentile(x,75)\n",
        "    iqr = q3-q1\n",
        "    floor = q1 - 1.5*iqr\n",
        "    ceiling = q3 + 1.5*iqr\n",
        "    outlier_indices = list(x.index[(x<floor) | (x > ceiling)])\n",
        "    outlier_values = list(x[outlier_indices])\n",
        "    return outlier_indices, outlier_values"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "\n",
        "### Stacking and Converting Into Tensors\n",
        "#[\"der_sex\",\"pos\",\"diag_admit\",\"diag1\",\"diag2\",\"diag3\",\"ndc\",\"rectype\",\"tos_flag\",\"pat_region\",\"pat_state\",\"prscbr_spec\"]\n",
        "cat_features=np.stack([df['quarter'],df['duration'],df['rectype'],df['bill_spec'],df['pos'],df['der_sex'],df['age_group'],df['formulary']],1)\n",
        "\n",
        "cat_features"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Convert Category Features to Torch Tensors"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "### Convert numpy to Tensors\n",
        "import torch\n",
        "cat_features=torch.tensor(cat_features,dtype=torch.int64)\n",
        "cat_features"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "df[\"target\"] = df[\"target\"].astype(\"float\")\n",
        "df[\"pat_age\"] = df[\"pat_age\"].astype(\"float\")\n",
        "df[\"pat_age\"].fillna(0)\n",
        "cont_features=[]\n",
        "\n",
        "for i in df.columns:\n",
        "    if i in [\"pat_age\"]:\n",
        "        cont_features.append(i)\n",
        "    else:\n",
        "        pass"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "\n",
        "### Stacking continuous variable to a tensor"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "\n",
        "cont_values=np.stack([df[i].values for i in cont_features],axis=1)\n",
        "cont_values=torch.tensor(cont_values,dtype=torch.float)\n",
        "cont_values"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Dependent Feature "
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "\n",
        "y=torch.tensor(df['target'].values,dtype=torch.float).reshape(-1,1)\n",
        "y"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "cat_features.shape,cont_values.shape,y.shape"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "#### Embedding Size For Categorical columns"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "cat_dims=[len(df[col].unique()) for col in [\"quarter\", \"duration\",\"rectype\",\"bill_spec\",\"pos\",\"der_sex\",\"age_group\",\"formulary\"]]"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "cat_dims"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "embedding_dim= [(x, min(50, (x + 1) \/\/ 2)) for x in cat_dims]"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "embedding_dim"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Defining the Embedding Layers"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "embed_representation=nn.ModuleList([nn.Embedding(inp,out) for inp,out in embedding_dim])\n",
        "embed_representation"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "embedding_val=[]\n",
        "for i,e in enumerate(embed_representation):\n",
        "    embedding_val.append(e(cat_features[:,i]))"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "z = torch.cat(embedding_val, 1)\n",
        "z"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "\n",
        "final_embed=z\n",
        "final_embed.shape"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "\n",
        "HEAP-DL has four hidden layers each having 50 neurons each. All layers uses a ReLU-activation step, BatchNorm1D also acts as a regularization step and a dropout rate of 0.2 during training. The categorical features were converted into feature embeddings and passed to the layer and there is a drop out of 0.2 applied to the embedding. The predicted target variable is a transformed sum value of paid, dispense and copay. The model was trained for 200 epochs and RMSE score, Target columns a derived numerical values which is  a sum of claims paid amount, pharmacy dispense_fee & patient copay since these are assumed to be the direct cost for the payer as per the IQVIA Pharmetrics data dictionary and user guide."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Create a Feed Forward Neural Network"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class FeedForwardNN(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, n_cont, out_sz, layers, p=0.5):\n",
        "        super().__init__()\n",
        "        self.embeds = nn.ModuleList([nn.Embedding(inp,out) for inp,out in embedding_dim])\n",
        "        self.emb_drop = nn.Dropout(p)\n",
        "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
        "        \n",
        "        layerlist = []\n",
        "        n_emb = sum((out for inp,out in embedding_dim))\n",
        "        n_in = n_emb + n_cont\n",
        "        \n",
        "        for i in layers:\n",
        "            #Linear Layer\n",
        "            layerlist.append(nn.Linear(n_in,i)) \n",
        "            \n",
        "            #ReLU Activation Layer\n",
        "            layerlist.append(nn.ReLU(inplace=True))\n",
        "\n",
        "            #BatchNorm 1D Layer - Regularization\n",
        "            layerlist.append(nn.BatchNorm1d(i))\n",
        "            \n",
        "            #DropOut Layer\n",
        "            layerlist.append(nn.Dropout(p))\n",
        "            n_in = i\n",
        "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
        "            \n",
        "        self.layers = nn.Sequential(*layerlist)\n",
        "    \n",
        "    def forward(self, x_cat, x_cont):\n",
        "        embeddings = []\n",
        "        for i,e in enumerate(self.embeds):\n",
        "            embeddings.append(e(x_cat[:,i]))\n",
        "        x = torch.cat(embeddings, 1)\n",
        "        x = self.emb_drop(x)\n",
        "        \n",
        "        x_cont = self.bn_cont(x_cont)\n",
        "        x = torch.cat([x, x_cont], 1)\n",
        "        x = self.layers(x)\n",
        "        return x"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Model Initialization"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "torch.manual_seed(100)"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### HEAP-DL Model Summary"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "import wandb\n",
        "wandb.init(project='heap-dl-experiements', entity='heap-dl-team1745')\n",
        "wandb.login()"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "sweep_config = {\n",
        "    'method': 'random'\n",
        "    }"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "metric = {\n",
        "    'name': 'loss',\n",
        "    'goal': 'minimize'   \n",
        "    }\n",
        "\n",
        "sweep_config['metric'] = metric"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "parameters_dict = {\n",
        "    'optimizer': {\n",
        "        'values': ['adam', 'sgd','adamw','rmsprop']\n",
        "        },\n",
        "    'fc1_layer_size': {\n",
        "        'values': [50, 100]\n",
        "        },\n",
        "    'fc2_layer_size': {\n",
        "        'values': [50, 100]\n",
        "        },\n",
        "    'fc3_layer_size': {\n",
        "        'values': [50, 100]\n",
        "        },\n",
        "    'fc4_layer_size': {\n",
        "        'values': [50, 100]\n",
        "        },\n",
        "    'dropout': {\n",
        "          'values': [0.1,0.2,0.3, 0.4, 0.5]\n",
        "        },\n",
        "    'loss_function':{\n",
        "        'values': ['MSE']\n",
        "    }\n",
        "    }\n",
        "\n",
        "sweep_config['parameters'] = parameters_dict"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "parameters_dict.update({\n",
        "    'epochs': {\n",
        "        'values': [100,200,300,500]}\n",
        "    })"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "import math\n",
        "\n",
        "parameters_dict.update({\n",
        "    'learning_rate': {\n",
        "        # a flat distribution between 0 and 0.1\n",
        "        'distribution': 'uniform',\n",
        "        'min': 0,\n",
        "        'max': 0.1\n",
        "      },\n",
        "    'batch_size': {\n",
        "        'values': [25000, 50000,75000,100000,125000, 135000]\n",
        "      },\n",
        "    'test_ratio': {\n",
        "        \n",
        "        'values': [0.10, 0.15, 0.20,0.25,0.30]\n",
        "      },\n",
        "    })"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "import pprint\n",
        "\n",
        "pprint.pprint(sweep_config)"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "def build_optimizer(network, optimizer, learning_rate):\n",
        "    if optimizer == \"sgd\":\n",
        "        optimizer = optim.SGD(network.parameters(),\n",
        "                              lr=learning_rate, momentum=0.9)\n",
        "    elif optimizer == \"adam\":\n",
        "        optimizer = optim.Adam(network.parameters(),\n",
        "                               lr=learning_rate)\n",
        "    elif optimizer ==\"adamw\":\n",
        "        optimizer = optim.AdamW(network.parameters(),\n",
        "                               lr=learning_rate)\n",
        "    elif optimizer ==\"rmsprop\":\n",
        "        optimizer = optim.RMSprop(network.parameters(),\n",
        "                               lr=learning_rate)\n",
        "    return optimizer\n",
        "\n",
        "def build_loss_function(network, loss):\n",
        "    if loss == \"MSE\":\n",
        "        loss_function=nn.MSELoss()\n",
        "   \n",
        "    return loss_function\n",
        "\n",
        "def build_network(fc1_layer_size,fc2_layer_size,fc3_layer_size,fc4_layer_size, dropout,embedding_dim, cont_features):\n",
        "    model=FeedForwardNN(embedding_dim,len(cont_features),1,[fc1_layer_size,fc2_layer_size,fc3_layer_size,fc4_layer_size],p=dropout)\n",
        "\n",
        "    return model\n",
        "\n",
        "def build_dataset(batch_size,test_ratio,categorical, continuos, y):\n",
        "    batch_size=batch_size\n",
        "    \n",
        "    test_size=int(batch_size*test_ratio)\n",
        "    data_categorical=categorical[:batch_size-test_size]\n",
        "    data_cont=continuos[:batch_size-test_size]\n",
        "    y_data=y[:batch_size-test_size]\n",
        "    \n",
        "    return data_categorical, data_cont, y_data"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Loss Function and Optimizer"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "sweep_id = wandb.sweep(sweep_config, project=\"heap-dl-experiements\", entity='heap-dl-team1745')"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# batch_size=50000\n",
        "# test_size=int(batch_size*0.15)\n",
        "# train_categorical=cat_features[:batch_size-test_size]\n",
        "# test_categorical=cat_features[batch_size-test_size:batch_size]\n",
        "# train_cont=cont_values[:batch_size-test_size]\n",
        "# test_cont=cont_values[batch_size-test_size:batch_size]\n",
        "# y_train=y[:batch_size-test_size]\n",
        "# y_test=y[batch_size-test_size:batch_size]"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "len(train_categorical),len(test_categorical),len(train_cont),len(test_cont),len(y_train),len(y_test)"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def train(config=None):\n",
        "    # Initialize a new wandb run\n",
        "    \n",
        "    with wandb.init(config=config):\n",
        "        # If called by wandb.agent, as below,\n",
        "        # this config will be set by Sweep Controller\n",
        "        config = wandb.config\n",
        "        final_losses=[]\n",
        "        #loader = build_dataset(config.batch_size)\n",
        "        model = build_network(config.fc1_layer_size,config.fc2_layer_size,config.fc3_layer_size,config.fc4_layer_size,config.dropout, embedding_dim, cont_features)\n",
        "        optimizer = build_optimizer(model, config.optimizer, config.learning_rate)\n",
        "        loss_function = build_loss_function(model, config.loss_function)\n",
        "        train_categorical = None\n",
        "        train_cont = None \n",
        "        y_train = None\n",
        "        train_categorical,train_cont,y_train = build_dataset(config.batch_size,config.test_ratio,cat_features, cont_values, y)\n",
        "        \n",
        "        model.train()\n",
        "        for i in range(config.epochs):\n",
        "            i=i+1\n",
        "            \n",
        "            y_pred=model(train_categorical,train_cont)\n",
        "            loss=torch.sqrt(loss_function(y_pred,y_train)) ### RMSE\n",
        "            wandb.log({\"loss\": loss, \"epoch\": i})   \n",
        "            final_losses.append(loss)\n",
        "            if i%10==1:\n",
        "                print(\"Epoch number: {} and the loss : {}\".format(i,loss.item()))\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "                    "
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "wandb.agent(sweep_id, train, count=150)"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### HEAP-DL Model Training"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# # Set Model in Training Mode\n",
        "# model.train()\n",
        "# epochs=200\n",
        "# final_losses=[]\n",
        "# for i in range(epochs):\n",
        "#     i=i+1\n",
        "#     y_pred=model(train_categorical,train_cont)\n",
        "#     loss=torch.sqrt(loss_function(y_pred,y_train)) ### RMSE\n",
        "#     wandb.log({\"loss\": loss})\n",
        "#     final_losses.append(loss)\n",
        "#     if i%10==1:\n",
        "#         print(\"Epoch number: {} and the loss : {}\".format(i,loss.item()))\n",
        "#     optimizer.zero_grad()\n",
        "#     loss.backward()\n",
        "#     optimizer.step()"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(range(epochs), final_losses)\n",
        "plt.ylabel('RMSE Loss')\n",
        "plt.xlabel('epoch');"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "#### Validate the Test Data\n",
        "HEAP-DL model acheived an **RMSE score of 7.74**"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Set Model in Evaluate Mode\n",
        "y_pred=\"\"\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred=model(test_categorical,test_cont)\n",
        "    loss=torch.sqrt(loss_function(y_pred,y_test))\n",
        "print('RMSE: {}'.format(loss))"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Test Prediction and Difference for Visualization"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "data_verify=pd.DataFrame(y_test.tolist(),columns=[\"Test\"])\n",
        "data_predicted=pd.DataFrame(y_pred.tolist(),columns=[\"Prediction\"])\n",
        "final_output=pd.concat([data_verify,data_predicted],axis=1)\n",
        "final_output['Difference']=final_output['Test']-final_output['Prediction']\n",
        "final_output.sample(3)"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(go.Scatter(x=final_output['Test'].index, y=final_output['Test'],\n",
        "                    mode='lines',\n",
        "                    name='Actual Value')))\n",
        "fig.add_trace(go.Scatter(go.Scatter(x=final_output['Prediction'].index, y=final_output['Prediction'],\n",
        "                    mode='lines',\n",
        "                    name='Test prediction')))\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis=dict(\n",
        "        showline=True,\n",
        "        showgrid=True,\n",
        "        showticklabels=False,\n",
        "        linecolor='white',\n",
        "        linewidth=1\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        title_text='Paid Amount',\n",
        "        titlefont=dict(\n",
        "            family='Rockwell',\n",
        "            size=12,\n",
        "            color='white',\n",
        "        ),\n",
        "        showline=True,\n",
        "        showgrid=True,\n",
        "        showticklabels=True,\n",
        "        linecolor='white',\n",
        "        linewidth=1,\n",
        "        ticks='outside',\n",
        "        tickfont=dict(\n",
        "            family='Rockwell',\n",
        "            size=12,\n",
        "            color='white',\n",
        "        ),\n",
        "    ),\n",
        "    showlegend=True,\n",
        "    template = 'plotly_dark'\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "annotations = []\n",
        "annotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,\n",
        "                              xanchor='left', yanchor='bottom',\n",
        "                              text='HEAP-DL Results',\n",
        "                              font=dict(family='Rockwell',\n",
        "                                        size=26,\n",
        "                                        color='white'),\n",
        "                              showarrow=False))\n",
        "fig.update_layout(annotations=annotations)\n",
        "\n",
        "fig.show()"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Saving the Model with State Dictionaries"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "torch.save(model.state_dict(),'\/data\/workspace_files\/model\/heapdl-baseline.pt')"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Loading model and using prior defined Embedding dimensions"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "embs_size=[(4, 2), (5, 3), (6, 3), (64, 32), (43, 22), (3, 2), (10, 5), (5, 3)]\n",
        "\n",
        "\n",
        "model1= FeedForwardNN(embs_size,len(cont_features),1,[50,50,50,50],p=0.2)\n",
        "model1.load_state_dict(torch.load('\/data\/workspace_files\/model\/heapdl-baseline.pt'))"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "model1"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## Integrated Gradients using Captum\n",
        "Reference: https:\/\/captum.ai\/docs\/introduction"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# imports from captum library\n",
        "from captum.attr import LayerConductance, LayerActivation, LayerIntegratedGradients\n",
        "from captum.attr import IntegratedGradients, DeepLift, GradientShap, NoiseTunnel, FeatureAblation\n",
        "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "lig = LayerIntegratedGradients(model1, model1.emb_drop)"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "attributions_start, delta_start = lig.attribute(inputs=(test_categorical,test_cont), baselines=(test_categorical,test_cont), return_convergence_delta=True)"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "ig_attr_test_sum = attributions_start.detach().numpy().sum(0)\n",
        "ig_attr_test_norm_sum = ig_attr_test_sum \/ np.linalg.norm(ig_attr_test_sum, ord=1)\n",
        "ig_attr_test_norm_sum.shape"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "x_axis_data = np.arange(72)\n",
        "#x_axis_data_labels = list(map(lambda idx: attributions_start[:,idx], x_axis_data))\n",
        "\n",
        "ig_attr_test_sum = attributions_start.detach().numpy().sum(0)\n",
        "ig_attr_test_norm_sum = ig_attr_test_sum \/ np.linalg.norm(ig_attr_test_sum, ord=1)\n",
        "\n",
        "lin_weight = model.layers[4].weight[0].detach().numpy()\n",
        "y_axis_lin_weight = lin_weight \/ np.linalg.norm(lin_weight, ord=1)\n",
        "\n",
        "width = 0.3\n",
        "legends = ['Int Grads']\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "\n",
        "ax = plt.subplot()\n",
        "ax.set_title('Comparing input feature importances across multiple algorithms and learned weights')\n",
        "ax.set_ylabel('Attributions')\n",
        "\n",
        "FONT_SIZE = 9\n",
        "plt.rc('font', size=FONT_SIZE)            # fontsize of the text sizes\n",
        "plt.rc('axes', titlesize=FONT_SIZE)       # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=FONT_SIZE)       # fontsize of the x and y labels\n",
        "plt.rc('legend', fontsize=FONT_SIZE - 4)  # fontsize of the legend\n",
        "\n",
        "ax.bar(x_axis_data[:70], ig_attr_test_norm_sum[:70], width, align='center', alpha=0.8, color='#eb5e7c')\n",
        "ax.autoscale_view()\n",
        "plt.tight_layout()\n",
        "\n",
        "ax.set_xticks(x_axis_data[:70])\n",
        "#ax.set_xticklabels(x_axis_data_labels)\n",
        "\n",
        "plt.legend(legends, loc=3)\n",
        "plt.show()"
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        
      ],
      "attachments":{
        
      },
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    }
  ],
  "metadata":{
    
  },
  "nbformat":4,
  "nbformat_minor":0
}